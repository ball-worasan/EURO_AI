{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612f5b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetConfig(csv_path='data_csv/EURUSD_D1.csv', time_candidates=('Time', 'time', 'date', 'datetime'), open_candidates=('Open', 'open', 'open_price'), high_candidates=('High', 'high'), low_candidates=('Low', 'low'), close_candidates=('Close', 'close', 'close_price'), volume_candidates=('Volume', 'volume', 'vol', 'tick_volume'), spread_candidates=('Spread', 'spread', 'sprd'), seq_len=24, horizon=1, train_ratio=0.7, val_ratio=0.15)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Call 1: ตั้งค่าเริ่มต้น + import library\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.max_columns\", 80)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    \"\"\"\n",
    "    config หลักของ dataset:\n",
    "    - csv_path: path ไฟล์ OHLCV\n",
    "    - seq_len: ความยาว sequence สำหรับ DL residual\n",
    "    - horizon: ทำนายล่วงหน้าอีกกี่แท่ง (default=1)\n",
    "    - train_ratio / val_ratio: time-based split\n",
    "    \"\"\"\n",
    "\n",
    "    csv_path: str = \"data_csv/EURUSD_D1.csv\"\n",
    "\n",
    "    time_candidates: Tuple[str, ...] = (\"Time\", \"time\", \"date\", \"datetime\")\n",
    "    open_candidates: Tuple[str, ...] = (\"Open\", \"open\", \"open_price\")\n",
    "    high_candidates: Tuple[str, ...] = (\"High\", \"high\")\n",
    "    low_candidates: Tuple[str, ...] = (\"Low\", \"low\")\n",
    "    close_candidates: Tuple[str, ...] = (\"Close\", \"close\", \"close_price\")\n",
    "    volume_candidates: Tuple[str, ...] = (\"Volume\", \"volume\", \"vol\", \"tick_volume\")\n",
    "    spread_candidates: Tuple[str, ...] = (\"Spread\", \"spread\", \"sprd\")\n",
    "\n",
    "    seq_len: int = 24\n",
    "    horizon: int = 1\n",
    "\n",
    "    train_ratio: float = 0.7\n",
    "    val_ratio: float = 0.15  # ส่วนที่เหลือเป็น test\n",
    "\n",
    "\n",
    "config = DatasetConfig()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b81735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Spread</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-11-26</th>\n",
       "      <td>1.51073</td>\n",
       "      <td>1.51381</td>\n",
       "      <td>1.49404</td>\n",
       "      <td>1.49682</td>\n",
       "      <td>70915</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-27</th>\n",
       "      <td>1.49653</td>\n",
       "      <td>1.49985</td>\n",
       "      <td>1.48264</td>\n",
       "      <td>1.49853</td>\n",
       "      <td>76695</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-30</th>\n",
       "      <td>1.49931</td>\n",
       "      <td>1.50825</td>\n",
       "      <td>1.49702</td>\n",
       "      <td>1.50343</td>\n",
       "      <td>79595</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-01</th>\n",
       "      <td>1.50351</td>\n",
       "      <td>1.51194</td>\n",
       "      <td>1.49719</td>\n",
       "      <td>1.50885</td>\n",
       "      <td>79059</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-02</th>\n",
       "      <td>1.50881</td>\n",
       "      <td>1.51096</td>\n",
       "      <td>1.50290</td>\n",
       "      <td>1.50635</td>\n",
       "      <td>80300</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open     High      Low    Close  Volume  Spread\n",
       "Time                                                          \n",
       "2009-11-26  1.51073  1.51381  1.49404  1.49682   70915       9\n",
       "2009-11-27  1.49653  1.49985  1.48264  1.49853   76695      11\n",
       "2009-11-30  1.49931  1.50825  1.49702  1.50343   79595       9\n",
       "2009-12-01  1.50351  1.51194  1.49719  1.50885   79059       9\n",
       "2009-12-02  1.50881  1.51096  1.50290  1.50635   80300       9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Call 2: โหลดข้อมูล EURUSD จาก CSV + เตรียม DataFrame ให้สะอาด\n",
    "# ============================\n",
    "\n",
    "\n",
    "def _search_csv_path(cfg: DatasetConfig) -> Path:\n",
    "    \"\"\"หาไฟล์ CSV แบบยืดหยุ่น (relative / ancestor)\"\"\"\n",
    "    cwd = Path.cwd()\n",
    "    for _ in range(6):\n",
    "        probe = cwd / cfg.csv_path\n",
    "        if probe.exists():\n",
    "            return probe\n",
    "        cwd = cwd.parent\n",
    "\n",
    "    candidates = [\n",
    "        Path(cfg.csv_path),\n",
    "        Path(\"..\") / cfg.csv_path,\n",
    "        Path.cwd() / cfg.csv_path,\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return c\n",
    "\n",
    "    return Path(cfg.csv_path)\n",
    "\n",
    "\n",
    "def _find_col_by_candidates(\n",
    "    df: pd.DataFrame, candidates: Tuple[str, ...]\n",
    ") -> Optional[str]:\n",
    "    \"\"\"หา column ใน df จาก list candidates (case-insensitive)\"\"\"\n",
    "    col_map_lower = {c.lower(): c for c in df.columns}\n",
    "    for name in candidates:\n",
    "        lower = name.lower()\n",
    "        if lower in col_map_lower:\n",
    "            return col_map_lower[lower]\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_ohlcv(cfg: DatasetConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    โหลด OHLCV แล้วรีเนมเป็นมาตรฐาน:\n",
    "      ['Time','Open','High','Low','Close','Volume','Spread']\n",
    "    ถ้าไม่มี Volume/Spread -> สร้างเป็น 0.0\n",
    "    \"\"\"\n",
    "    csv_path = _search_csv_path(cfg)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, sep=None, engine=\"python\")\n",
    "    except Exception:\n",
    "        df = pd.read_csv(csv_path, sep=\"\\t\", engine=\"python\")\n",
    "\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    time_col = _find_col_by_candidates(df, cfg.time_candidates)\n",
    "    open_col = _find_col_by_candidates(df, cfg.open_candidates)\n",
    "    high_col = _find_col_by_candidates(df, cfg.high_candidates)\n",
    "    low_col = _find_col_by_candidates(df, cfg.low_candidates)\n",
    "    close_col = _find_col_by_candidates(df, cfg.close_candidates)\n",
    "    volume_col = _find_col_by_candidates(df, cfg.volume_candidates)\n",
    "    spread_col = _find_col_by_candidates(df, cfg.spread_candidates)\n",
    "\n",
    "    missing = [\n",
    "        name\n",
    "        for name, col in (\n",
    "            (\"Open\", open_col),\n",
    "            (\"High\", high_col),\n",
    "            (\"Low\", low_col),\n",
    "            (\"Close\", close_col),\n",
    "        )\n",
    "        if col is None\n",
    "    ]\n",
    "    if time_col is None:\n",
    "        raise KeyError(f\"Time column not found. Available: {df.columns.tolist()}\")\n",
    "    if missing:\n",
    "        raise KeyError(\n",
    "            f\"Missing required OHLC columns: {missing}. Available: {df.columns.tolist()}\"\n",
    "        )\n",
    "\n",
    "    rename_map = {\n",
    "        time_col: \"Time\",\n",
    "        open_col: \"Open\",\n",
    "        high_col: \"High\",\n",
    "        low_col: \"Low\",\n",
    "        close_col: \"Close\",\n",
    "    }\n",
    "    if volume_col is not None:\n",
    "        rename_map[volume_col] = \"Volume\"\n",
    "    if spread_col is not None:\n",
    "        rename_map[spread_col] = \"Spread\"\n",
    "\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    if \"Volume\" not in df.columns:\n",
    "        df[\"Volume\"] = 0.0\n",
    "    if \"Spread\" not in df.columns:\n",
    "        df[\"Spread\"] = 0.0\n",
    "\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "\n",
    "    numeric_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Spread\"]\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    df = df.sort_values(\"Time\").reset_index(drop=True)\n",
    "    df = df.set_index(\"Time\")\n",
    "\n",
    "    return df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Spread\"]]\n",
    "\n",
    "\n",
    "raw_df = load_ohlcv(config)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b17e927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Spread</th>\n",
       "      <th>ret_1</th>\n",
       "      <th>ret_4</th>\n",
       "      <th>ret_12</th>\n",
       "      <th>ema_20</th>\n",
       "      <th>ema_50</th>\n",
       "      <th>ema_100</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>atr_14</th>\n",
       "      <th>vol_20</th>\n",
       "      <th>candle_body</th>\n",
       "      <th>candle_range</th>\n",
       "      <th>upper_wick</th>\n",
       "      <th>lower_wick</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>session_asia</th>\n",
       "      <th>session_london</th>\n",
       "      <th>session_ny</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-12-24</th>\n",
       "      <td>1.43331</td>\n",
       "      <td>1.44180</td>\n",
       "      <td>1.43278</td>\n",
       "      <td>1.43767</td>\n",
       "      <td>79350</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.306290</td>\n",
       "      <td>0.281103</td>\n",
       "      <td>-2.138739</td>\n",
       "      <td>1.458305</td>\n",
       "      <td>1.476832</td>\n",
       "      <td>1.485852</td>\n",
       "      <td>33.781100</td>\n",
       "      <td>0.013414</td>\n",
       "      <td>0.558658</td>\n",
       "      <td>0.00436</td>\n",
       "      <td>0.00902</td>\n",
       "      <td>0.00413</td>\n",
       "      <td>0.00053</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-25</th>\n",
       "      <td>1.43761</td>\n",
       "      <td>1.44365</td>\n",
       "      <td>1.43558</td>\n",
       "      <td>1.43772</td>\n",
       "      <td>75425</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.656706</td>\n",
       "      <td>-2.425583</td>\n",
       "      <td>1.456345</td>\n",
       "      <td>1.475299</td>\n",
       "      <td>1.484899</td>\n",
       "      <td>33.829254</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>0.555922</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00807</td>\n",
       "      <td>0.00593</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-28</th>\n",
       "      <td>1.43726</td>\n",
       "      <td>1.44138</td>\n",
       "      <td>1.43505</td>\n",
       "      <td>1.43719</td>\n",
       "      <td>80135</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.036864</td>\n",
       "      <td>0.842701</td>\n",
       "      <td>-2.414531</td>\n",
       "      <td>1.454521</td>\n",
       "      <td>1.473804</td>\n",
       "      <td>1.483954</td>\n",
       "      <td>33.550741</td>\n",
       "      <td>0.011971</td>\n",
       "      <td>0.543394</td>\n",
       "      <td>-0.00007</td>\n",
       "      <td>0.00633</td>\n",
       "      <td>0.00412</td>\n",
       "      <td>0.00214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-29</th>\n",
       "      <td>1.43723</td>\n",
       "      <td>1.44572</td>\n",
       "      <td>1.43311</td>\n",
       "      <td>1.43386</td>\n",
       "      <td>80669</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.231702</td>\n",
       "      <td>0.040467</td>\n",
       "      <td>-1.865692</td>\n",
       "      <td>1.452553</td>\n",
       "      <td>1.472238</td>\n",
       "      <td>1.482962</td>\n",
       "      <td>31.780362</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.525736</td>\n",
       "      <td>-0.00337</td>\n",
       "      <td>0.01261</td>\n",
       "      <td>0.00849</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-30</th>\n",
       "      <td>1.43397</td>\n",
       "      <td>1.43606</td>\n",
       "      <td>1.42694</td>\n",
       "      <td>1.43384</td>\n",
       "      <td>79328</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.001395</td>\n",
       "      <td>-0.266403</td>\n",
       "      <td>-2.165695</td>\n",
       "      <td>1.450771</td>\n",
       "      <td>1.470732</td>\n",
       "      <td>1.481989</td>\n",
       "      <td>31.769519</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.528453</td>\n",
       "      <td>-0.00013</td>\n",
       "      <td>0.00912</td>\n",
       "      <td>0.00209</td>\n",
       "      <td>0.00690</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open     High      Low    Close  Volume  Spread     ret_1     ret_4    ret_12    ema_20    ema_50   ema_100     rsi_14  \\\n",
       "Time                                                                                                                                    \n",
       "2009-12-24  1.43331  1.44180  1.43278  1.43767   79350     9.0  0.306290  0.281103 -2.138739  1.458305  1.476832  1.485852  33.781100   \n",
       "2009-12-25  1.43761  1.44365  1.43558  1.43772   75425     9.0  0.003478  0.656706 -2.425583  1.456345  1.475299  1.484899  33.829254   \n",
       "2009-12-28  1.43726  1.44138  1.43505  1.43719   80135    11.0 -0.036864  0.842701 -2.414531  1.454521  1.473804  1.483954  33.550741   \n",
       "2009-12-29  1.43723  1.44572  1.43311  1.43386   80669    11.0 -0.231702  0.040467 -1.865692  1.452553  1.472238  1.482962  31.780362   \n",
       "2009-12-30  1.43397  1.43606  1.42694  1.43384   79328    11.0 -0.001395 -0.266403 -2.165695  1.450771  1.470732  1.481989  31.769519   \n",
       "\n",
       "              atr_14    vol_20  candle_body  candle_range  upper_wick  lower_wick  hour  dayofweek  session_asia  session_london  \\\n",
       "Time                                                                                                                               \n",
       "2009-12-24  0.013414  0.558658      0.00436       0.00902     0.00413     0.00053     0          3             1               0   \n",
       "2009-12-25  0.012914  0.555922      0.00011       0.00807     0.00593     0.00203     0          4             1               0   \n",
       "2009-12-28  0.011971  0.543394     -0.00007       0.00633     0.00412     0.00214     0          0             1               0   \n",
       "2009-12-29  0.012092  0.525736     -0.00337       0.01261     0.00849     0.00075     0          1             1               0   \n",
       "2009-12-30  0.012194  0.528453     -0.00013       0.00912     0.00209     0.00690     0          2             1               0   \n",
       "\n",
       "            session_ny  \n",
       "Time                    \n",
       "2009-12-24           0  \n",
       "2009-12-25           0  \n",
       "2009-12-28           0  \n",
       "2009-12-29           0  \n",
       "2009-12-30           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Call 3: ฟีเจอร์พื้นฐาน + ATR + volatility + session + candle\n",
    "# ============================\n",
    "\n",
    "\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    return series.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "\n",
    "def rsi(series: pd.Series, window: int = 14) -> pd.Series:\n",
    "    delta = series.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "\n",
    "    avg_gain = gain.ewm(alpha=1 / window, adjust=False).mean()\n",
    "    avg_loss = loss.ewm(alpha=1 / window, adjust=False).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss.replace(0, 1e-10)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "\n",
    "def atr(\n",
    "    high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14\n",
    ") -> pd.Series:\n",
    "    prev_close = close.shift(1)\n",
    "    tr1 = high - low\n",
    "    tr2 = (high - prev_close).abs()\n",
    "    tr3 = (low - prev_close).abs()\n",
    "    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    # ถ้าอยากใช้ Wilder ATR จริง ๆ ให้เปลี่ยนเป็น ewm\n",
    "    return true_range.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "\n",
    "def add_basic_features(df: pd.DataFrame, cfg: DatasetConfig) -> pd.DataFrame:\n",
    "    open_ = df[\"Open\"]\n",
    "    high = df[\"High\"]\n",
    "    low = df[\"Low\"]\n",
    "    close = df[\"Close\"]\n",
    "\n",
    "    # short-term returns (%)\n",
    "    df[\"ret_1\"] = close.pct_change(1) * 100\n",
    "    df[\"ret_4\"] = close.pct_change(4) * 100\n",
    "    df[\"ret_12\"] = close.pct_change(12) * 100\n",
    "\n",
    "    # EMA\n",
    "    df[\"ema_20\"] = ema(close, 20)\n",
    "    df[\"ema_50\"] = ema(close, 50)\n",
    "    df[\"ema_100\"] = ema(close, 100)\n",
    "\n",
    "    # RSI\n",
    "    df[\"rsi_14\"] = rsi(close, 14)\n",
    "\n",
    "    # ATR + rolling volatility\n",
    "    df[\"atr_14\"] = atr(high, low, close, window=14)\n",
    "    df[\"vol_20\"] = df[\"ret_1\"].rolling(window=20, min_periods=20).std()\n",
    "\n",
    "    # Candle anatomy\n",
    "    candle_body = close - open_\n",
    "    candle_range = high - low\n",
    "    is_bull = candle_body >= 0\n",
    "\n",
    "    upper_wick = np.where(is_bull, high - close, high - open_)\n",
    "    lower_wick = np.where(is_bull, open_ - low, close - low)\n",
    "\n",
    "    df[\"candle_body\"] = candle_body\n",
    "    df[\"candle_range\"] = candle_range\n",
    "    df[\"upper_wick\"] = upper_wick\n",
    "    df[\"lower_wick\"] = lower_wick\n",
    "\n",
    "    # Time/session features (ถ้า D1 แล้ว hour คงที่ อาจตัดออกทีหลัง)\n",
    "    df[\"hour\"] = df.index.hour\n",
    "    df[\"dayofweek\"] = df.index.dayofweek\n",
    "\n",
    "    hour = df[\"hour\"]\n",
    "    df[\"session_asia\"] = ((hour >= 0) & (hour < 8)).astype(int)\n",
    "    df[\"session_london\"] = ((hour >= 8) & (hour < 16)).astype(int)\n",
    "    df[\"session_ny\"] = ((hour >= 16) & (hour < 24)).astype(int)\n",
    "\n",
    "    df[\"Spread\"] = df[\"Spread\"].astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_feat = add_basic_features(raw_df.copy(), config)\n",
    "df_feat = df_feat.dropna().copy()\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0172e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gap_next</th>\n",
       "      <th>range_next</th>\n",
       "      <th>body_next</th>\n",
       "      <th>upper_wick_next</th>\n",
       "      <th>lower_wick_next</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-12-24</th>\n",
       "      <td>-0.00006</td>\n",
       "      <td>0.00807</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00593</td>\n",
       "      <td>0.00203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-25</th>\n",
       "      <td>-0.00046</td>\n",
       "      <td>0.00633</td>\n",
       "      <td>-0.00007</td>\n",
       "      <td>0.00412</td>\n",
       "      <td>0.00214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-28</th>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.01261</td>\n",
       "      <td>-0.00337</td>\n",
       "      <td>0.00849</td>\n",
       "      <td>0.00075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-29</th>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00912</td>\n",
       "      <td>-0.00013</td>\n",
       "      <td>0.00209</td>\n",
       "      <td>0.00690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-30</th>\n",
       "      <td>-0.00007</td>\n",
       "      <td>0.01375</td>\n",
       "      <td>-0.00094</td>\n",
       "      <td>0.01023</td>\n",
       "      <td>0.00258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gap_next  range_next  body_next  upper_wick_next  lower_wick_next\n",
       "Time                                                                         \n",
       "2009-12-24  -0.00006     0.00807    0.00011          0.00593          0.00203\n",
       "2009-12-25  -0.00046     0.00633   -0.00007          0.00412          0.00214\n",
       "2009-12-28   0.00004     0.01261   -0.00337          0.00849          0.00075\n",
       "2009-12-29   0.00011     0.00912   -0.00013          0.00209          0.00690\n",
       "2009-12-30  -0.00007     0.01375   -0.00094          0.01023          0.00258"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Call 4: สร้าง targets โครงสร้างสำหรับวันถัดไป (gap/range/body + wick)\n",
    "# ============================\n",
    "\n",
    "\n",
    "def add_struct_targets(df: pd.DataFrame, cfg: DatasetConfig) -> pd.DataFrame:\n",
    "    h = cfg.horizon\n",
    "\n",
    "    df[\"Open_next\"] = df[\"Open\"].shift(-h)\n",
    "    df[\"High_next\"] = df[\"High\"].shift(-h)\n",
    "    df[\"Low_next\"] = df[\"Low\"].shift(-h)\n",
    "    df[\"Close_next\"] = df[\"Close\"].shift(-h)\n",
    "\n",
    "    # targets โครงสร้าง\n",
    "    df[\"gap_next\"] = df[\"Open_next\"] - df[\"Close\"]  # Close_t -> Open_next\n",
    "    df[\"range_next\"] = df[\"High_next\"] - df[\"Low_next\"]\n",
    "    df[\"body_next\"] = df[\"Close_next\"] - df[\"Open_next\"]\n",
    "\n",
    "    # wick ของวันถัดไป (ให้ DL เรียน)\n",
    "    df[\"upper_wick_next\"] = df[\"High_next\"] - df[[\"Open_next\", \"Close_next\"]].max(\n",
    "        axis=1\n",
    "    )\n",
    "    df[\"lower_wick_next\"] = df[[\"Open_next\", \"Close_next\"]].min(axis=1) - df[\"Low_next\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_all = add_struct_targets(df_feat.copy(), config)\n",
    "df_all = df_all.dropna().copy()\n",
    "df_all[\n",
    "    [\"gap_next\", \"range_next\", \"body_next\", \"upper_wick_next\", \"lower_wick_next\"]\n",
    "].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81faab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting: (4160, 24) (4160, 3)\n",
      "DL seq: (4136, 24, 24) (4136, 5) DatetimeIndex(['2010-01-27', '2010-01-28', '2010-01-29'], dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Call 5: สร้าง dataset\n",
    "#   A) Boosting (tabular)\n",
    "#   B) DL Residual (sequence)\n",
    "# ============================\n",
    "\n",
    "# ฟีเจอร์ตาม meta ของคุณ\n",
    "feature_cols: List[str] = [\n",
    "    \"Open\",\n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"Close\",\n",
    "    \"Volume\",\n",
    "    \"Spread\",\n",
    "    \"ret_1\",\n",
    "    \"ret_4\",\n",
    "    \"ret_12\",\n",
    "    \"ema_20\",\n",
    "    \"ema_50\",\n",
    "    \"ema_100\",\n",
    "    \"rsi_14\",\n",
    "    \"atr_14\",\n",
    "    \"vol_20\",\n",
    "    \"candle_body\",\n",
    "    \"candle_range\",\n",
    "    \"upper_wick\",\n",
    "    \"lower_wick\",\n",
    "    \"hour\",\n",
    "    \"dayofweek\",\n",
    "    \"session_asia\",\n",
    "    \"session_london\",\n",
    "    \"session_ny\",\n",
    "]\n",
    "\n",
    "# ----- A) Boosting dataset -----\n",
    "X_boost = df_all[feature_cols].to_numpy(dtype=np.float32)\n",
    "y_boost = df_all[[\"gap_next\", \"range_next\", \"body_next\"]].to_numpy(dtype=np.float32)\n",
    "boost_index = df_all.index  # เวลา input t (target = t+1 ตามนิยามคอลัมน์)\n",
    "\n",
    "print(\"Boosting:\", X_boost.shape, y_boost.shape)\n",
    "\n",
    "\n",
    "# ----- B) DL sequence dataset -----\n",
    "def build_sequence_dataset_residual(\n",
    "    df: pd.DataFrame,\n",
    "    cfg: DatasetConfig,\n",
    "    feature_cols: List[str],\n",
    ") -> Tuple[np.ndarray, np.ndarray, pd.DatetimeIndex]:\n",
    "    \"\"\"\n",
    "    X_seq: [num_samples, seq_len, num_features]\n",
    "    y_dl:  [num_samples, 5] = [gap_next, range_next, body_next, upper_wick_next, lower_wick_next]\n",
    "      *ตรงนี้เป็น \"true targets\" ก่อนทำ residual\n",
    "      หลัง train boosting แล้วค่อยแปลง 3 ตัวแรกเป็น residual\n",
    "    target_index = เวลา target (t+horizon) ของ sample นั้น\n",
    "    \"\"\"\n",
    "\n",
    "    data_feat = df[feature_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "    y_true = df[\n",
    "        [\"gap_next\", \"range_next\", \"body_next\", \"upper_wick_next\", \"lower_wick_next\"]\n",
    "    ].to_numpy(dtype=np.float32)\n",
    "\n",
    "    index_values = df.index.to_numpy()\n",
    "    seq_len = cfg.seq_len\n",
    "    horizon = cfg.horizon\n",
    "    n_rows = len(df)\n",
    "\n",
    "    num_samples = n_rows - seq_len - horizon + 1\n",
    "    if num_samples <= 0:\n",
    "        raise ValueError(\"Not enough rows for given seq_len and horizon.\")\n",
    "\n",
    "    num_features = data_feat.shape[1]\n",
    "    X_seq = np.empty((num_samples, seq_len, num_features), dtype=np.float32)\n",
    "    y_dl = np.empty((num_samples, 5), dtype=np.float32)\n",
    "    idx_list = []\n",
    "\n",
    "    out_idx = 0\n",
    "    # i = last index of input window (เวลา t)\n",
    "    for i in range(seq_len - 1, n_rows - horizon):\n",
    "        start = i - (seq_len - 1)\n",
    "        end = i + 1\n",
    "\n",
    "        # target ของ sample นี้ใช้ที่แถว i (นิยามไว้ว่าเป็น t -> t+1 แล้ว)\n",
    "        X_seq[out_idx] = data_feat[start:end]\n",
    "        y_dl[out_idx] = y_true[i]\n",
    "        idx_list.append(index_values[i + horizon])  # เวลาแท่งที่ถูกทำนายจริง\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    assert out_idx == num_samples\n",
    "    target_index = pd.DatetimeIndex(idx_list)\n",
    "    return X_seq, y_dl, target_index\n",
    "\n",
    "\n",
    "X_seq, y_dl_true, target_index = build_sequence_dataset_residual(\n",
    "    df_all, config, feature_cols\n",
    ")\n",
    "print(\"DL seq:\", X_seq.shape, y_dl_true.shape, target_index[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6693cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost Train: (2912, 24) (2912, 3)\n",
      "Boost Val:   (624, 24) (624, 3)\n",
      "Boost Test:  (624, 24) (624, 3)\n",
      "DL Train: (2895, 24, 24) (2895, 5)\n",
      "DL Val:   (620, 24, 24) (620, 5)\n",
      "DL Test:  (621, 24, 24) (621, 5)\n",
      "hour nunique: 1\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Call 6: time-based split (train / val / test) สำหรับทั้ง Boosting และ DL\n",
    "# ============================\n",
    "\n",
    "\n",
    "def time_based_split_array(arr: np.ndarray, cfg: DatasetConfig):\n",
    "    n = len(arr)\n",
    "    train_end = int(n * cfg.train_ratio)\n",
    "    val_end = train_end + int(n * cfg.val_ratio)\n",
    "    return arr[:train_end], arr[train_end:val_end], arr[val_end:]\n",
    "\n",
    "\n",
    "# ----- Boosting split -----\n",
    "Xb_train, Xb_val, Xb_test = time_based_split_array(X_boost, config)\n",
    "yb_train, yb_val, yb_test = time_based_split_array(y_boost, config)\n",
    "idxb_train, idxb_val, idxb_test = (\n",
    "    boost_index[: len(Xb_train)],\n",
    "    boost_index[len(Xb_train) : len(Xb_train) + len(Xb_val)],\n",
    "    boost_index[len(Xb_train) + len(Xb_val) :],\n",
    ")\n",
    "\n",
    "print(\"Boost Train:\", Xb_train.shape, yb_train.shape)\n",
    "print(\"Boost Val:  \", Xb_val.shape, yb_val.shape)\n",
    "print(\"Boost Test: \", Xb_test.shape, yb_test.shape)\n",
    "\n",
    "# ----- DL split -----\n",
    "Xs_train, Xs_val, Xs_test = time_based_split_array(X_seq, config)\n",
    "yd_train_true, yd_val_true, yd_test_true = time_based_split_array(y_dl_true, config)\n",
    "idxs_train, idxs_val, idxs_test = (\n",
    "    target_index[: len(Xs_train)],\n",
    "    target_index[len(Xs_train) : len(Xs_train) + len(Xs_val)],\n",
    "    target_index[len(Xs_train) + len(Xs_val) :],\n",
    ")\n",
    "\n",
    "print(\"DL Train:\", Xs_train.shape, yd_train_true.shape)\n",
    "print(\"DL Val:  \", Xs_val.shape, yd_val_true.shape)\n",
    "print(\"DL Test: \", Xs_test.shape, yd_test_true.shape)\n",
    "\n",
    "# Diagnostic: ถ้า hour มีค่าเดียว (D1 แท้) ให้พิจารณาตัดฟีเจอร์เวลา\n",
    "print(\"hour nunique:\", df_all[\"hour\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80fb9a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved NPZ dataset to: /Users/thanaporn/Desktop/EURO_H1_AI/prepared_datasets/boosting_dl_residual/eurusd_struct_sequences.npz\n",
      "✔ Saved meta JSON to: /Users/thanaporn/Desktop/EURO_H1_AI/prepared_datasets/boosting_dl_residual/eurusd_struct_meta.json\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Call 7: เซฟ dataset (.npz + meta.json) สำหรับ Boosting + DL Residual\n",
    "# ============================\n",
    "\n",
    "save_dir = Path(\"../../prepared_datasets/boosting_dl_residual\").resolve()\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "npz_path = save_dir / \"eurusd_struct_sequences.npz\"\n",
    "np.savez_compressed(\n",
    "    npz_path,\n",
    "    # ---- Boosting tabular ----\n",
    "    Xb_train=Xb_train,\n",
    "    Xb_val=Xb_val,\n",
    "    Xb_test=Xb_test,\n",
    "    yb_train=yb_train,\n",
    "    yb_val=yb_val,\n",
    "    yb_test=yb_test,\n",
    "    idxb_train=np.array(idxb_train.astype(str)),\n",
    "    idxb_val=np.array(idxb_val.astype(str)),\n",
    "    idxb_test=np.array(idxb_test.astype(str)),\n",
    "    # ---- DL sequences (true targets; residual จะทำหลัง boost pred) ----\n",
    "    Xs_train=Xs_train,\n",
    "    Xs_val=Xs_val,\n",
    "    Xs_test=Xs_test,\n",
    "    yd_train_true=yd_train_true,\n",
    "    yd_val_true=yd_val_true,\n",
    "    yd_test_true=yd_test_true,\n",
    "    idxs_train=np.array(idxs_train.astype(str)),\n",
    "    idxs_val=np.array(idxs_val.astype(str)),\n",
    "    idxs_test=np.array(idxs_test.astype(str)),\n",
    ")\n",
    "\n",
    "print(f\"✔ Saved NPZ dataset to: {npz_path}\")\n",
    "\n",
    "meta = {\n",
    "    \"csv_path\": config.csv_path,\n",
    "    \"seq_len\": config.seq_len,\n",
    "    \"horizon\": config.horizon,\n",
    "    \"train_ratio\": config.train_ratio,\n",
    "    \"val_ratio\": config.val_ratio,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"columns_required\": [\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Spread\"],\n",
    "    \"targets_boosting\": [\"gap_next\", \"range_next\", \"body_next\"],\n",
    "    \"targets_dl_true\": [\n",
    "        \"gap_next\",\n",
    "        \"range_next\",\n",
    "        \"body_next\",\n",
    "        \"upper_wick_next\",\n",
    "        \"lower_wick_next\",\n",
    "    ],\n",
    "    \"note\": \"DL targets are TRUE values; convert first 3 to residual after boosting predictions.\",\n",
    "}\n",
    "\n",
    "meta_path = save_dir / \"eurusd_struct_meta.json\"\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✔ Saved meta JSON to: {meta_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forex-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
